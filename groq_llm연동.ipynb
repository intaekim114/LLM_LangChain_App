{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95060012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1fa19dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5e91b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"LangServe는 무엇인가요? 자세하게 설명해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "846007cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001F78263A360> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F7827BD2B0> root_client=<openai.OpenAI object at 0x000001F7FF9D8320> root_async_client=<openai.AsyncOpenAI object at 0x000001F78232B8F0> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa69856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답: LangServe는 LangChain이라는 프레임워크를 기반으로 구축된 오픈 소스 라이브러리입니다. LangChain은 자연어 처리(NLP) 및 생성 AI 애플리케이션을 개발하기 위한 프레임워크로, 대규모 언어 모델(LLM)을 활용하여 애플리케이션을 구축할 수 있습니다.\n",
      "\n",
      "LangServe는 LangChain을 사용하여 구축된 애플리케이션을 쉽게 배포하고 관리할 수 있도록 설계되었습니다. 이 라이브러리는 개발자가 LangChain을 사용하여 구축한 애플리케이션을 클라우드 환경에서 쉽게 배포하고, API를 통해 다른 서비스와 통합할 수 있도록 지원합니다.\n",
      "\n",
      "LangServe의 주요 기능은 다음과 같습니다:\n",
      "\n",
      "1. **LangChain 애플리케이션 배포**: LangServe를 사용하면 LangChain을 사용하여 구축된 애플리케이션을 쉽게 배포할 수 있습니다. 개발자는 LangServe를 사용하여 애플리케이션을 클라우드 환경에서 배포하고 관리할 수 있습니다.\n",
      "2. **API 통합**: LangServe는 API를 제공하여 다른 서비스와의 통합을 지원합니다. 이를 통해 개발자는 LangServe를 사용하여 구축된 애플리케이션을 다른 서비스와 쉽게 통합할 수 있습니다.\n",
      "3. **모니터링 및 로그 관리**: LangServe는 애플리케이션의 모니터링 및 로그 관리를 지원합니다. 이를 통해 개발자는 애플리케이션의 성능을 모니터링하고 문제를 빠르게 식별할 수 있습니다.\n",
      "4. **확장성**: LangServe는 수평적 확장성을 지원합니다. 즉, 애플리케이션의 수요가 증가하면 LangServe를 사용하여 쉽게 확장할 수 있습니다.\n",
      "\n",
      "LangServe를 사용하는 이유는 다음과 같습니다:\n",
      "\n",
      "1. **빠른 배포**: LangServe를 사용하면 LangChain 애플리케이션을 빠르게 배포할 수 있습니다.\n",
      "2. **쉬운 관리**: LangServe는 애플리케이션의 관리 및 모니터링을 쉽게 해줍니다.\n",
      "3. **확장성**: LangServe는 애플리케이션의 확장성을 제공합니다.\n",
      "\n",
      "전반적으로, LangServe는 LangChain을 사용하여 구축된 애플리케이션을 쉽게 배포하고 관리할 수 있는 라이브러리입니다. 이를 통해 개발자는 LangChain의 강력한 기능을 활용하여 자연어 처리 및 생성 AI 애플리케이션을 빠르게 구축하고 배포할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "try:    # llm 호출\n",
    "    response = llm.invoke(prompt_text) \n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03333b28",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM을 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93694e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='\\n    You are an expert in AI Expert. Answer the question. \\n    <Question>: {input}에 대해 쉽게 한글로 설명해주세요.\\n    ')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an expert in AI Expert. Answer the question. \n",
    "    <Question>: {input}에 대해 쉽게 한글로 설명해주세요.\n",
    "    \"\"\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5a86543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cea524",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM + OuterParser를 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a89111af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "output_parser = StrOutputParser()\n",
    "chain2 = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c723132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 방식과 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습하고, 패턴을 발견하며, 미래의 새로운 데이터에 대해 예측하거나 결정을 내릴 수 있도록 하는 것이죠.\n",
      "\n",
      "쉽게 설명하면, 인공지능 모델의 학습 과정은 다음과 같습니다:\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해, 많은 양의 데이터를 수집합니다. 이 데이터는 과거의 경험이나 관찰을 통해 얻어진 정보입니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집된 데이터를 깨끗하게 정리하고, 필요한 경우 데이터를 변환하거나 특징을 추출합니다. 이를 통해 모델이 학습하기 좋은 형태로 데이터를 준비합니다.\n",
      "\n",
      "3. **모델 설정**: 학습을 진행할 인공지능 모델을 설정합니다. 모델은 신경망, 결정 트리, 선형 회귀 등 다양한 형태가 있을 수 있습니다.\n",
      "\n",
      "4. **학습**: 준비된 데이터를 모델에 입력하고, 모델이 데이터의 패턴을 학습하도록 합니다. 이 과정에서는 모델이 데이터에 맞게 자신의 내부 파라미터(예: 신경망의 가중치)를 조정합니다. 학습의 목표는 모델의 예측과 실제 값 사이의 오류를 최소화하는 것입니다.\n",
      "\n",
      "5. **평가**: 학습이 완료된 후, 모델의 성능을 평가합니다. 이는 학습 데이터와는 별도로 준비한 테스트 데이터를 사용하여 수행합니다. 평가를 통해 모델이 얼마나 잘 학습했는지, 그리고 새로운 데이터에 대해 얼마나 잘 예측하는지 확인합니다.\n",
      "\n",
      "6. **튜닝**: 모델의 성능이 만족스럽지 않을 경우, 하이퍼파라미터를 조정하거나 모델 구조를 변경하는 등 추가적인 튜닝 작업을 수행합니다.\n",
      "\n",
      "예를 들어, 자율 주행 자동차의 경우, 수많은 도로 상황, 보행자, 차량 등의 데이터를 수집하고, 이를 통해 자동차가 상황에 맞게 적절하게 반응하도록 학습시키는 것입니다. 처음에는 자동차가 보행자를 인식하지 못하거나 신호를 잘못 인식할 수 있지만, 지속적인 학습을 통해 자동차는 점점 더 똑똑해지고, 다양한 상황에 대처할 수 있게 됩니다.\n",
      "\n",
      "이처럼 인공지능 모델은 주어진 데이터를 통해 학습하고, 그 학습을 통해 새로운 상황에 대해 예측하거나 결정을 내리는 능력을 키웁니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "    print(type(result))\n",
    "    print(result.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb609ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "LangChain은 인공지능(AI) 기술을 기반으로 하는 제품군을 제공하는 회사입니다. LangChain의 제품은 주로 자연어 처리(NLP) 및 대규모 언어 모델(LLM) 기반의 애플리케이션과 서비스를 개발하고 지원하는 데 중점을 두고 있습니다. 아래는 LangChain의 주요 제품 및 서비스에 대한 설명입니다.\n",
      "\n",
      "1. **LangChain 플랫폼**: LangChain의 핵심 플랫폼은 개발자가 자연어 처리 애플리케이션을 쉽게 구축할 수 있도록 설계되었습니다. 이 플랫폼은 대규모 언어 모델을 활용하여 텍스트 분석, 생성, 이해 등 다양한 자연어 처리 작업을 지원합니다.\n",
      "\n",
      "2. **LangChain API**: LangChain은 다양한 자연어 처리 작업을 위한 API를 제공합니다. 이 API를 통해 개발자는 텍스트 요약, 질문 답변, 감정 분석, 언어 번역 등 여러 가지 기능을 애플리케이션에 통합할 수 있습니다.\n",
      "\n",
      "3. **LLM(Large Language Model) 기반 솔루션**: LangChain은 특정 산업이나 사용 사례에 맞게 조정된 다양한 LLM 기반 솔루션을 제공합니다. 이러한 솔루션은 고객 서비스 자동화, 콘텐츠 생성, 데이터 분석 등 다양한 분야에서 활용될 수 있습니다.\n",
      "\n",
      "4. **개발자 도구**: LangChain은 개발자가 더 쉽게 자연어 처리 애플리케이션을 개발할 수 있도록 지원하는 다양한 도구들을 제공합니다. 이러한 도구에는 모델 훈련 데이터셋, 개발 프레임워크, 디버깅 도구 등이 포함될 수 있습니다.\n",
      "\n",
      "5. **엔터프라이즈 솔루션**: 기업을 위한 맞춤형 솔루션도 LangChain의 제품군에 포함됩니다. 이러한 솔루션은 대기업이나 기관이 자체적으로 자연어 처리 능력을 갖추고, 자사의 데이터와 프로세스에 AI를 통합할 수 있도록 설계되었습니다.\n",
      "\n",
      "LangChain의 제품과 서비스는 자연어 처리와 인공지능 기술을 활용하여 비즈니스 프로세스를 자동화하고, 고객 경험을 개선하며, 콘텐츠 생성과 데이터 분석을 효율적으로 수행할 수 있도록 지원합니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain2.invoke({\"input\": \"LangChain의 Product(제품)에는 어떤 것들이 있나요?\"})\n",
    "    print(type(result))\n",
    "    print(result) # output parser라서 스트링으로 바로 나옴\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee094ccd",
   "metadata": {},
   "source": [
    "### Runnable의 stream() 함수 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867594c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "try:\n",
    "    answer = chain2.stream({\"input\": \"인공지능 모델의 학습 원리를 자세하게 설명해 주세요.\"})\n",
    "\n",
    "    # 스트리밍 출력\n",
    "    print(answer)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n",
    "\n",
    "# for token in answer:\n",
    "#     # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "#     print(token, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
