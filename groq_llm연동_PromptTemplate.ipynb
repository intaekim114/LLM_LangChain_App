{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95060012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1fa19dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e5e91b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"LangServe는 무엇인가요? 자세하게 설명해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "846007cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001ACEF4AD670> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001ACEF5797C0> root_client=<openai.OpenAI object at 0x000001ACEEE75A00> root_async_client=<openai.AsyncOpenAI object at 0x000001ACEF4DBAA0> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffa69856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답: LangServe는 개발자가 대규모 언어 모델(LLM)을 쉽게 배포하고 관리할 수 있도록 도와주는 플랫폼입니다. LangServe를 사용하면 개발자는 LLM을 기반으로 한 애플리케이션을 빠르게 구축하고, 이를 효율적으로 운영할 수 있습니다.\n",
      "\n",
      "LangServe의 주요 기능은 다음과 같습니다:\n",
      "\n",
      "1. **LLM 배포**: LangServe를 사용하면 개발자는 다양한 LLM을 쉽게 배포할 수 있습니다. LangServe는 여러 LLM 프레임워크를 지원하며, 개발자는 선호하는 프레임워크를 선택하여 LLM을 배포할 수 있습니다.\n",
      "\n",
      "2. **API 제공**: LangServe는 LLM을 위한 RESTful API를 자동으로 생성해 줍니다. 이를 통해 개발자는 LLM을 다른 애플리케이션과 쉽게 통합할 수 있습니다. API를 사용하면 클라이언트 측에서 쉽게 LLM에 접근하고, 요청을 보낼 수 있습니다.\n",
      "\n",
      "3. **관리 및 모니터링**: LangServe는 LLM의 성능을 모니터링하고 관리할 수 있는 기능을 제공합니다. 개발자는 LangServe를 통해 LLM의 사용량, 응답 시간, 오류율 등을 실시간으로 확인하고, 필요에 따라 모델을 업데이트하거나 파라미터를 조정할 수 있습니다.\n",
      "\n",
      "4. **안전성 및 보안**: LangServe는 데이터 보안과 안전성을 중요하게 생각합니다. LangServe는 데이터 암호화, 접근 제어, 보안 인증 등의 기능을 제공하여 LLM과 관련된 데이터를 안전하게 보호합니다.\n",
      "\n",
      "5. **확장성**: LangServe는 수평적 확장성을 지원합니다. 즉, 증가하는 트래픽이나 데이터에 대응하기 위해 LangServe에 배포된 LLM을 쉽게 확장할 수 있습니다.\n",
      "\n",
      "6. **통합 개발 환경**: LangServe는 통합 개발 환경을 제공하여 개발자가 더욱 효율적으로 작업할 수 있도록 돕습니다. 개발자는 LangServe의 개발 도구를 사용하여 모델을 개발, 테스트, 배포할 수 있습니다.\n",
      "\n",
      "LangServe를 이용하면 개발자는 LLM의 기술적인 부분에 집중하지 않고, 애플리케이션의 개발 및 비즈니스 로직에 더 집중할 수 있습니다. LangServe는 오픈 소스 프레임워크로 제공되며, 개발자는 LangServe를 자유롭게 수정하고 확장할 수 있습니다.\n",
      "\n",
      "LangServe의 사용 사례는 매우 다양합니다. 예를 들어, 챗봇 개발, 자연어 처리(NLP) 애플리케이션 개발, 콘텐츠 생성, 언어 번역, 질의응답 시스템 개발 등이 있습니다.\n",
      "\n",
      "결론적으로, LangServe는 대규모 언어 모델을 쉽게 배포, 관리, 확장할 수 있는 플랫폼으로, 개발자가 LLM 기반 애플리케이션을 효율적으로 구축하고 운영하는 데 큰 도움이 됩니다.\n"
     ]
    }
   ],
   "source": [
    "try:    # llm 호출\n",
    "    response = llm.invoke(prompt_text) \n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03333b28",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM을 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93694e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='\\n    You are an expert in AI Expert. Answer the question. \\n    <Question>: {input}에 대해 쉽게 한글로 설명해주세요.\\n    ')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an expert in AI Expert. Answer the question. \n",
    "    <Question>: {input}에 대해 쉽게 한글로 설명해주세요.\n",
    "    \"\"\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a86543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cea524",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM + OuterParser를 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a89111af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "output_parser = StrOutputParser()\n",
    "chain2 = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c723132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "인공지능 모델의 학습 원리는 컴퓨터가 데이터를 통해 스스로 학습하고, 더 나은 결정을 내릴 수 있도록 만드는 과정입니다. 쉽게 말해, 인공지능 모델이 처음에는 모르는 것을 배우는 과정이라고 생각하시면 됩니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해서는 많은 데이터가 필요합니다. 이 데이터는 문제에 대한 답이나 레이블이 달린 형태로 제공됩니다. 예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. 이 경우, 수많은 고양이와 강아지의 사진, 그리고 각 사진이 고양이인지 강아지인지를 나타내는 레이블이 필요합니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집한 데이터를 모델이 이해할 수 있는 형태로 변환하는 과정입니다. 이 과정에는 데이터 정리, 변환, 선택 등이 포함될 수 있습니다.\n",
      "\n",
      "3. **모델 선택**: 학습에 사용할 알고리즘 또는 모델을 선택합니다. 이 선택은 문제의 성격, 데이터의 유형 등에 따라 달라집니다. 예를 들어, 이미지 분류 문제에는 합성곱 신경망(CNN)이 자주 사용됩니다.\n",
      "\n",
      "4. **학습**: 모델에 데이터를 입력하고, 모델이 데이터를 분석하여 오류를 최소화하는 방향으로 스스로를 조정하도록 합니다. 이 과정은 '손실 함수(loss function)'를 통해 모델의 성능을 평가하고, '최적화 알고리즘'을 통해 모델의 파라미터를 조정하는 방식으로 진행됩니다.\n",
      "\n",
      "5. **평가**: 학습이 완료된 모델이 얼마나 잘 작동하는지 평가합니다. 이를 위해 학습에 사용되지 않은 별도의 테스트 데이터를 사용합니다. 모델의 성능이 만족할 만한 수준이면, 실제 문제 해결에 사용할 수 있습니다.\n",
      "\n",
      "예를 들어, 어린 아이에게 고양이와 강아지를 구별하는 법을 가르친다고 가정해 봅시다. \n",
      "\n",
      "- **데이터 수집**: 많은 고양이와 강아지의 사진을 보여주고, 각각 이것이 고양이라고, 혹은 강아지라고 말해줍니다. \n",
      "- **데이터 전처리**: 사진의 크기나 품질 등을 조정하여 아이가 더 쉽게 이해할 수 있도록 합니다.\n",
      "- **모델 선택**: 이 경우는 아이의 뇌가 스스로 패턴을 학습할 수 있도록 하는 것으로, 인공지능에서는 신경망 모델을 선택하는 것에 비유할 수 있습니다.\n",
      "- **학습**: 고양이라고 말해준 사진이 고양이처럼 생겼는지, 강아지라고 말해준 사진이 강아지처럼 생겼는지 반복적으로 보여주고, 틀린 경우에는 다시 설명해줍니다. \n",
      "- **평가**: 새로운 고양이와 강아지의 사진을 보여주었을 때, 아이가 올바르게 구별할 수 있다면 학습이 잘된 것입니다.\n",
      "\n",
      "이처럼 인공지능 모델의 학습 원리는 컴퓨터가 데이터를 통해 스스로 학습하고, 더 나은 결정을 내릴 수 있도록 만드는 과정입니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "    print(type(result))\n",
    "    print(result.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb609ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "LangChain은 인공지능(AI) 모델을 활용하여 자연어 처리(NLP) 및 대화형 인공지능 시스템을 개발하는 플랫폼입니다. LangChain의 제품에는 다음과 같은 것들이 있습니다:\n",
      "\n",
      "1. **LangChain 플랫폼**: LangChain은 개발자가 대화형 AI 모델을 쉽게 구축, 훈련 및 배포할 수 있는 플랫폼을 제공합니다. 이 플랫폼은 다양한 AI 모델과 도구를 지원하며, 개발자가 자신만의 대화형 AI 시스템을 만들 수 있도록 돕습니다.\n",
      "\n",
      "2. **LangChain API**: LangChain API는 개발자가 자연어 처리 및 대화형 AI 기능을 자신의 애플리케이션에 통합할 수 있도록 지원하는 API입니다. 이 API를 통해 개발자는 LangChain의 AI 모델을 활용하여 텍스트 분석, 감정 분석, 대화 생성 등 다양한 기능을 구현할 수 있습니다.\n",
      "\n",
      "3. **LangChain Studio**: LangChain Studio는 대화형 AI 모델을 개발하고 훈련하는 데 사용되는 통합 개발 환경(IDE)입니다. 이 도구를 통해 개발자는 AI 모델을 쉽게 구축, 테스트 및 배포할 수 있습니다.\n",
      "\n",
      "4. **LangChain 모델**: LangChain은 다양한 사전 훈련된 AI 모델을 제공합니다. 이러한 모델은 자연어 처리, 대화 생성, 감정 분석 등 다양한 작업에 사용할 수 있습니다. 개발자는 이러한 모델을 활용하여 자신의 애플리케이션에 대화형 AI 기능을 추가할 수 있습니다.\n",
      "\n",
      "LangChain의 제품들은 개발자가 대화형 AI 시스템을 쉽게 구축하고 배포할 수 있도록 지원하며, 자연어 처리 및 AI 기술의 발전을 촉진합니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain2.invoke({\"input\": \"LangChain의 Product(제품)에는 어떤 것들이 있나요?\"})\n",
    "    print(type(result))\n",
    "    print(result) # output parser라서 스트링으로 바로 나옴\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee094ccd",
   "metadata": {},
   "source": [
    "### Runnable의 stream() 함수 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "867594c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리를 쉽게 설명해 드리겠습니다.\n",
      "\n",
      "**인공지능 모델의 학습 원리**\n",
      "\n",
      "인공지능 모델의 학습은 데이터를 통해 모델이 스스로 학습하고, 예측이나 분류를 잘하도록 만드는 과정입니다. 이를 위해서는 다음과 같은 단계가 필요합니다.\n",
      "\n",
      "### 1. 데이터 수집\n",
      "\n",
      "인공지능 모델을 학습시키기 위해서는 많은 양의 데이터가 필요합니다. 이 데이터는 문제에 따라 다양한 형태가 될 수 있습니다. 예를 들어, 이미지 분류 모델을 만든다면, 다양한 물건의 이미지들이 필요합니다.\n",
      "\n",
      "### 2. 데이터 전처리\n",
      "\n",
      "수집한 데이터를 모델이 학습할 수 있도록 가공하는 과정입니다. 데이터를 정제하고, 변환하여 모델에 입력할 수 있는 형태로 만드는 것입니다.\n",
      "\n",
      "### 3. 모델 선택\n",
      "\n",
      "어떤 유형의 모델을 사용할지 결정합니다. 예를 들어, 이미지 분류 문제라면 합성곱 신경망(CNN), 자연어 처리 문제라면 순환 신경망(RNN)이나 트랜스포머 모델을 사용할 수 있습니다.\n",
      "\n",
      "### 4. 모델 학습\n",
      "\n",
      "모델에 데이터를 입력하고, 모델이 스스로 학습하도록 합니다. 이 과정에서는 다음과 같은 일들이 일어납니다.\n",
      "\n",
      "* **손실 함수 정의**: 모델의 예측 결과와 실제 값의 차이(손실)를 계산하는 함수를 정의합니다. 이 손실 함수를 최소화하는 것이 목표입니다.\n",
      "* **최적화 알고리즘**: 손실 함수를 최소화하기 위해 모델의 가중치를 업데이트하는 알고리즘을 사용합니다. 대표적인 최적화 알고리즘에는 경사 하강법(Gradient Descent) 등이 있습니다.\n",
      "\n",
      "### 5. 모델 평가\n",
      "\n",
      "학습이 완료된 모델을 평가합니다. 평가 데이터에 모델을 적용하여 성능을 측정하고, 필요에 따라 모델을 수정하거나 재학습합니다.\n",
      "\n",
      "### 6. 모델 배포\n",
      "\n",
      "최종적으로 모델을 배포하여 실제 문제에 적용합니다.\n",
      "\n",
      "**핵심 개념**\n",
      "\n",
      "* **신경망**: 인공지능 모델의 핵심은 신경망입니다. 신경망은 여러 층의 노드(또는 뉴런)로 구성되어 있으며, 각 노드는 입력 값을 받아서 출력 값을 생성합니다.\n",
      "* **가중치**: 신경망의 노드 사이에는 가중치가 있습니다. 가중치는 입력 값에 곱해져서 출력 값에 영향을 줍니다.\n",
      "* **활성화 함수**: 각 노드에서는 활성화 함수를 사용하여 출력 값을 생성합니다. 활성화 함수는 입력 값을 변환하여 출력 값을 만들어냅니다.\n",
      "\n",
      "**학습 과정**\n",
      "\n",
      "모델의 학습 과정은 다음과 같습니다.\n",
      "\n",
      "1. 입력 데이터를 모델에 입력합니다.\n",
      "2. 모델은 입력 데이터를 처리하여 출력 값을 생성합니다.\n",
      "3. 손실 함수를 계산하여 모델의 성능을 평가합니다.\n",
      "4. 최적화 알고리즘을 사용하여 모델의 가중치를 업데이트합니다.\n",
      "5. 1~4 단계를 반복하여 모델의 성능을 향상시킵니다.\n",
      "\n",
      "이렇게 인공지능 모델은 데이터를 통해 학습하고, 예측이나 분류를 잘하도록 만드는 것입니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "try:\n",
    "    answer = chain2.stream({\"input\": \"인공지능 모델의 학습 원리를 자세하게 설명해 주세요.\"})\n",
    "\n",
    "    # 스트리밍 출력\n",
    "    # print(answer)\n",
    "\n",
    "    for token in answer:\n",
    "        # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "        print(token, end=\"\", flush=True)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a1e5ef",
   "metadata": {},
   "source": [
    "### Multi Chain\n",
    "* 첫번째 Chain의 출력이, 두번째 Chain의 입력이 된다.\n",
    "* 두개의 Chain과 Prompt + OutputParser를 LCEL로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c922be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추전한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 줄거리를 3문장으로 요약해 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a66bab6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영화의 제목은 'A Moment to Remember'입니다.\n",
      "\n",
      "'A Moment to Remember'는 사랑과 기억, 가족에 관한 감동적인 드라마입니다. 어린 시절에 처음 만난 수진과 민우는 수진이 교통사고로 기억을 잃은 후에도 민우의 사랑은 계속됩니다. 영화는 두 사람의 로맨틱한 사랑 이야기와 수진의 기억 상실로 인한 감동적인 장면들로 구성되어 많은 사람들에게 감동을 선사합니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "try:\n",
    "    chain2 = (\n",
    "        {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "        | prompt2\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "    response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ed46dc",
   "metadata": {},
   "source": [
    "### PromptTemplate 여러개 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f97c8658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "ChatGPT 모델은 대규모 언어 데이터셋을 기반으로 학습된 생성 모델입니다. 이 모델은 주어진 문맥에 따라 다음에 올 수 있는 단어를 예측하도록 학습되며, 이를 통해 자연스러운 대화 흐름을 생성할 수 있습니다. 학습 과정에서 모델은 많은 양의 텍스트 데이터를 분석하고 패턴을 학습하여 언어 이해 및 생성 능력을 키웁니다.\n",
      "\n",
      "ChatGPT 모델의 장점은 다음과 같습니다.\n",
      "\n",
      "* 자연스러운 대화 생성: ChatGPT 모델은 사람처럼 자연스러운 대화 흐름을 생성할 수 있습니다.\n",
      "* 지식 기반 답변: ChatGPT 모델은 다양한 분야에 대한 지식을 학습하여 사용자의 질문에 답변할 수 있습니다.\n",
      "* 창의적 콘텐츠 생성: ChatGPT 모델은 창의적인 콘텐츠, 예를 들어 시나 이야기 등을 생성할 수 있습니다.\n",
      "\n",
      "ChatGPT 모델과 비슷한 AI 모델은 다음과 같습니다.\n",
      "\n",
      "* LLaMA\n",
      "* PaLM\n",
      "* BERT\n",
      "* transformer-XL\n",
      "* Megatron-LM\n",
      "\n",
      "이 모델들은 모두 자연어 처리 및 생성에 중점을 둔 AI 모델이며, ChatGPT와 유사한 기술을 사용하여 개발되었습니다.\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 요약해서 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"영어\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"영어\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed578600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 2 문장으로 요약해서 한국어로 답변해 주세요.', 'Gemma 모델의 학습 원리를 3 문장으로 요약해서 한국어로 답변해 주세요.', 'llama-4 모델의 학습 원리를 4 문장으로 요약해서 한국어로 답변해 주세요.']\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 요약해서 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 2},\n",
    "    {\"model_name\": \"Gemma\", \"count\": 3},\n",
    "    {\"model_name\": \"llama-4\", \"count\": 4}\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions] # q가 dict 타입 **의 의미는 dict가 넘어갈 때 사용\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b289869a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 모델은 대규모의 텍스트 데이터를 학습하여 언어 패턴과 구조를 익히는 방식으로 작동합니다. 이 모델은 주어진 문맥에서 다음에 올 가능성이 높은 단어를 예측하도록 훈련되며, 이를 통해 자연스럽고 일관된 텍스트를 생성할 수 있습니다.\n",
      "Gemma 모델은 주어진 문맥을 기반으로 다음 토큰을 예측하는 자기 지도 학습(auto-regressive) 방식의 트랜스포머 아키텍처를 사용합니다. 언어 모델링을 위해 특별히 설계된 이 모델은 대규모 데이터 세트에 대해 학습되었으며, 다양한 자연어 처리 작업에 활용될 수 있습니다. Gemma는 학습을 위해 대규모 텍스트 데이터 세트를 활용하며, 이 과정에서 모델은 언어의 패턴과 구조를 학습하게 됩니다.\n",
      "llama-4 모델은 메타에서 개발한 대규모 언어 모델입니다. 이 모델은 방대한 텍스트 데이터를 기반으로 학습되며, 이를 통해 자연어 처리 능력을 습득합니다. 학습 과정에서 모델은 입력된 텍스트의 패턴과 구조를 분석하고, 이를 바탕으로 다음에 나타날 단어 또는 문장을 예측합니다. 이처럼 llama-4 모델은 다양한 텍스트 데이터를 학습함으로써 자연어 이해 및 생성 능력을 키우게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    response = llm.invoke(prompt)\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf95a3",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePrompt Template 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df10a7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "**딥러닝**은 인공신경망을 기반으로 하는 머신러닝의 한 분야입니다. 딥러닝은 데이터에서 패턴을 학습하고, 이를 바탕으로 예측이나 분류 작업을 수행할 수 있습니다. 특히 이미지, 음성, 자연어 처리와 같은 분야에서 뛰어난 성능을 발휘합니다.\n",
      "\n",
      "### 딥러닝의 핵심 개념\n",
      "\n",
      "1. **인공신경망**: 딥러닝은 다층 퍼셉트론이라는 인공신경망 구조를 사용합니다. 이 구조는 입력층, 하나 이상의 은닉층, 출력층으로 구성되어 있습니다.\n",
      "2. **은닉층**: 딥러닝의 '딥'은 여러 개의 은닉층을 의미합니다. 은닉층은 데이터에서 복잡한 패턴을 학습하는 역할을 합니다.\n",
      "3. **활성화 함수**: 각 층의 출력은 활성화 함수를 통해 비선형으로 변환됩니다. 대표적인 활성화 함수로는 ReLU, sigmoid, tanh 등이 있습니다.\n",
      "4. **백프로파게이션**: 딥러닝은 오류를 역전파하여 네트워크의 가중치를 업데이트하는 방식으로 학습합니다.\n",
      "\n",
      "### 딥러닝의 학습 과정\n",
      "\n",
      "1. **데이터 수집**: 학습에 필요한 데이터를 수집합니다.\n",
      "2. **데이터 전처리**: 데이터를 정규화하거나 변환하여 학습에 적합한 형태로 만듭니다.\n",
      "3. **모델 정의**: 딥러닝 모델의 구조를 정의합니다.\n",
      "4. **학습**: 데이터를 모델에 입력하여 학습합니다. 모델은 오류를 최소화하기 위해 가중치를 조정합니다.\n",
      "5. **평가**: 학습된 모델의 성능을 평가합니다.\n",
      "\n",
      "### 딥러닝의 응용 분야\n",
      "\n",
      "- **이미지 인식**: 얼굴 인식, 객체 탐지, 이미지 분류 등\n",
      "- **자연어 처리**: 언어 번역, 감성 분석, 챗봇 등\n",
      "- **음성 인식**: 음성 텍스트 변환, 음성 명령 인식 등\n",
      "\n",
      "딥러닝은 최근 몇 년간 급격한 발전을 이루어냈으며, 다양한 산업 분야에서 활용되고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"당신은 {topic} 전문가 입니다. 명확하고 자세하게 설명해 주세요.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"딥러닝은 무엇인가요?\")\n",
    "\n",
    "# LLM 호출\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc32518",
   "metadata": {},
   "source": [
    "### FewShotPromptTemlate\n",
    "* 예시를 제공하는 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f50dfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 태양계의 행성들\n",
      "1. **수성**: 태양과 가장 가까운 행성으로, 매우 작은 크기와 높은 온도를 가지고 있습니다.\n",
      "2. **금성**: 밝고 뜨거운 행성으로, 두꺼운 대기로 인해 표면이 잘 보이지 않습니다.\n",
      "3. **지구**: 생명체가 살고 있는 유일한 행성입니다.\n",
      "4. **화성**: 붉은 행성으로, 과거에는 물이 있었다고 추정됩니다.\n",
      "5. **목성**: 태양계에서 가장 큰 행성으로, 가스 거인입니다.\n",
      "6. **토성**: 아름다운 고리를 가진 가스 거인입니다.\n",
      "7. **천왕성**: 자전축이 기울어진 얼음 거인입니다.\n",
      "8. **해왕성**: 가장 먼 행성으로, 강한 바람과 추운 온도를 가지고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "model = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "chain = final_prompt | model\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"태양계의 행성들을 간략히 정리해 주세요.\"})\n",
    "#result = chain.invoke({\"input\": \"양자 얽힘이 무엇인가요?\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06b41a",
   "metadata": {},
   "source": [
    "### PartialPrompt Template\n",
    "* 프롬프트의 입력값에 동적인 함수 호출 이나 외부 API를 호출한 동적인 값을 대입할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d397043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 계절: 겨울\n",
      "🔹 프롬프트: input_variables=['season'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['season'], input_types={}, partial_variables={}, template='{season}에 주로 발생하는 대표적인 지구과학 현상 3가지를 알려주세요.각 현상에 대해 간단한 설명을 포함해주세요.'), additional_kwargs={})]\n",
      "🔹 모델 응답: 겨울에 발생하는 자연현상: \n",
      " 1.  **극광** *   **설명:** 태양풍이 지구 자기장과 상호 작용하여 극지방에서 발생합니다. 북극에서는 북극광, 남극에서는 남극광으로 불리며, 밤하늘에 다채로운 빛을 발합니다. *   **특징:** 극광은 주로 밤하늘에 나타나며, 녹색, 빨간색, 보라색 등 다양한 색상을 띕니다. 극광은 태양 활동이 활발한 시기에 더 자주 발생합니다.\n",
      "2.  **빙하** *   **설명:** 빙하는 높은 산이나 극지방에서 형성되는 큰 얼음 덩어리입니다. 빙하는 지구 온난화로 인해 녹고 있으며, 해수면 상승에 영향을 미칩니다. *   **특징:** 빙하는 극지방과 높은 산에서 주로 발생하며, 빙하의 녹는 속도는 기후 변화에 따라 달라집니다.\n",
      "3.  **눈과 얼음** *   **설명:** 겨울에는 기온이 낮아지면서 눈과 얼음이 형성됩니다. 눈은 대기 중의 수증기가 얼어서 떨어지는 것이고, 얼음은 물이 얼어서 형성됩니다. *   **특징:** 눈과 얼음은 겨울철 교통사고의 원인이 될 수 있으며, 농작물에도 피해를 줄 수 있습니다. 또한, 눈과 얼음은 지구 온난화로 인해 점점 더 줄어들고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "    \n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# 프롬프트 템플릿 정의 (부분 변수 적용)\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"{season}에 일어나는 대표적인 지구과학 현상은 {phenomenon}입니다.\",\n",
    "#     input_variables=[\"phenomenon\"],  # 사용자 입력 필요\n",
    "#     partial_variables={\"season\": get_current_season()}  # 동적으로 계절 값 할당\n",
    "# )\n",
    "season = get_current_season(\"south\")\n",
    "print(f\"현재 계절: {season}\")\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"{season}에 주로 발생하는 대표적인 지구과학 현상 3가지를 알려주세요.\"\n",
    "    \"각 현상에 대해 간단한 설명을 포함해주세요.\"\n",
    "    )\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# 특정 계절의 현상 질의\n",
    "chain = (\n",
    "    {\"season\": lambda x:season}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "result = chain.invoke({})\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"🔹 프롬프트: {prompt}\")\n",
    "print(f\"🔹 모델 응답: {season}에 발생하는 자연현상: \\n {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b9cc7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 프롬프트: 현재 1달러 = 1374.55원 기준으로 환율 정보를 알려드립니다. 현재 환율을 기준으로 한국 경제에 미치는 영향 및 향후에 환율의 예상값에 대한 분석을 제공해 주세요.\n",
      "🔹 모델 응답: ## 1. 한국 경제에 미치는 영향\n",
      "\n",
      "### (1) 수출\n",
      "\n",
      "*   **수출 증가:** 약달러는 한국의 수출 경쟁력을 높여주어 수출 증가로 이어질 수 있습니다. \n",
      "*   **원화 가치 하락:** 원화 가치가 하락하면 한국 상품의 가격이 해외 시장에서 더 저렴해져 수출이 증가할 수 있습니다.\n",
      "\n",
      "### (2) 수입\n",
      "\n",
      "*   **수입 가격 상승:** 달러 강세는 수입 물가를 상승시켜 한국 경제에 부담을 줄 수 있습니다. \n",
      "*   **원화 가치 하락:** 원화 가치가 하락하면 수입 상품의 가격이 상승하여 물가 상승 압력을 가중시킬 수 있습니다.\n",
      "\n",
      "### (3) 물가\n",
      "\n",
      "*   **물가 상승:** 수입 물가가 상승하면 국내 물가 상승으로 이어질 수 있습니다. \n",
      "*   **원화 가치 하락:** 원화 가치 하락은 수입 물가를 상승시켜 물가 상승 압력을 가중시킬 수 있습니다.\n",
      "\n",
      "### (4) 외국인 투자\n",
      "\n",
      "*   **외국인 투자 감소:** 달러 강세는 외국인 투자 감소로 이어질 수 있습니다. \n",
      "*   **원화 가치 하락:** 원화 가치 하락은 외국인 투자자에게 한국 시장에 대한 투자 매력을 감소시킬 수 있습니다.\n",
      "\n",
      "### (5) 금리\n",
      "\n",
      "*   **금리 인상:** 달러 강세는 금리 인상으로 이어질 수 있습니다. \n",
      "*   **원화 가치 하락:** 원화 가치 하락은 물가 상승 압력을 가중시켜 금리 인상 필요성을 높일 수 있습니다.\n",
      "\n",
      "## 2. 향후 환율 예상\n",
      "\n",
      "### (1) 글로벌 경제 상황\n",
      "\n",
      "*   **미국 경제:** 미국 경제의 성장세와 인플레이션 상황, 연방준비제도(Fed)의 통화 정책 결정이 달러화 가치에 영향을 미칠 것입니다.\n",
      "*   **한국 경제:** 한국의 경제 성장세, 물가 상황, 한국은행의 통화 정책 결정이 원화 가치에 영향을 미칠 것입니다.\n",
      "\n",
      "### (2) 지정학적 리스크\n",
      "\n",
      "*   **글로벌 불확실성:** 글로벌 경제 불확실성, 지정학적 리스크 등 다양한 요인들이 환율 변동에 영향을 미칠 것입니다.\n",
      "\n",
      "### (3) 원유 가격\n",
      "\n",
      "*   **원유 가격 변동:** 원유 가격 변동은 인플레이션과 경제 성장에 영향을 미쳐 환율에 영향을 줄 수 있습니다.\n",
      "\n",
      "## 3. 종합 분석\n",
      "\n",
      "현재 환율 수준은 1달러 = 1374.55원입니다. 이는 최근 몇 년간 원화 가치의 약세를 반영하는 수치입니다. 원화 약세는 수출 증가로 이어질 수 있지만, 수입 물가 상승과 물가 상승 압력을 가중시킬 수 있습니다.\n",
      "\n",
      "향후 환율 전망은 불확실합니다. 미국 경제의 성장세와 인플레이션 상황, 연방준비제도(Fed)의 통화 정책 결정, 한국의 경제 성장세, 물가 상황, 한국은행의 통화 정책 결정 등 다양한 요인들이 환율 변동에 영향을 미칠 것입니다.\n",
      "\n",
      "투자자들은 이러한 요인들을 주의 깊게 모니터링하고, 투자 전략을 수립해야 할 것입니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 실시간 환율을 가져오는 함수\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1달러 = {data['rates']['KRW']}원\"\n",
    "\n",
    "# {info} 변수에 API에서 받은 환율 정보를 동적으로 반영\n",
    "prompt = PromptTemplate(\n",
    "    template=\"현재 {info} 기준으로 환율 정보를 알려드립니다. 현재 환율을 기준으로 한국 경제에 미치는 영향 및 향후에 환율의 예상값에 대한 분석을 제공해 주세요.\",\n",
    "    input_variables=[],  # 사용자 입력 없음\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # API에서 가져온 데이터 자동 반영\n",
    ")\n",
    "\n",
    "# LLM 모델 설정 (GPT-4o-mini 사용)\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# 모델에 프롬프트 전달 및 응답 받기\n",
    "response = model.invoke(prompt.format())\n",
    "\n",
    "# 결과 출력\n",
    "print(\"🔹 프롬프트:\", prompt.format())\n",
    "print(\"🔹 모델 응답:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
