{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95060012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1fa19dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e5e91b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"LangServe는 무엇인가요? 자세하게 설명해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "846007cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001F7829DB530> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F78332ABA0> root_client=<openai.OpenAI object at 0x000001F7829C4290> root_async_client=<openai.AsyncOpenAI object at 0x000001F78332BE30> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffa69856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답: LangServe는 개발자가 대규모 언어 모델(LLM)을 쉽게 배포하고 관리할 수 있도록 지원하는 오픈 소스 라이브러리입니다. LangServe를 사용하면 개발자는 언어 모델을 API 서버로 쉽게 전환하여 다양한 애플리케이션에서 언어 모델을 사용할 수 있습니다.\n",
      "\n",
      "LangServe의 주요 기능은 다음과 같습니다:\n",
      "\n",
      "1. **LLM 통합**: LangServe는 다양한 LLM 프레임워크(Hugging Face, LangChain 등)와 통합됩니다. 이를 통해 개발자는 자신이 선호하는 프레임워크를 사용하여 모델을 개발하고 LangServe를 통해 배포할 수 있습니다.\n",
      "\n",
      "2. **API 서버 생성**: LangServe는 언어 모델을 API 서버로 변환합니다. 이를 통해 클라이언트 애플리케이션에서 HTTP 요청을 통해 언어 모델을 호출할 수 있습니다.\n",
      "\n",
      "3. **자동화된 API 엔드포인트 생성**: LangServe는 언어 모델의 입력 및 출력 스키마를 자동으로 감지하여 API 엔드포인트를 생성합니다. 이 기능은 개발자가 API 엔드포인트를 수동으로 정의할 필요가 없도록 해줍니다.\n",
      "\n",
      "4. **JSON 모드 및 스트리밍 지원**: LangServe는 JSON 모드와 스트리밍을 지원하여 클라이언트 애플리케이션에서 언어 모델의 출력을 효율적으로 처리할 수 있습니다.\n",
      "\n",
      "5. **보안 및 인증**: LangServe는 API 키 인증과 같은 보안 기능을 제공하여 언어 모델에 대한 무단 액세스를 제한할 수 있습니다.\n",
      "\n",
      "6. **관찰 가능성**: LangServe는 모델 성능에 대한 모니터링 및 로깅 기능을 제공하여 개발자가 모델의 동작을 더 잘 이해하고 문제를 빠르게 식별할 수 있도록 돕습니다.\n",
      "\n",
      "LangServe를 사용하는 주요 이점은 다음과 같습니다:\n",
      "\n",
      "*   대규모 언어 모델을 빠르고 쉽게 배포할 수 있습니다.\n",
      "*   언어 모델을 다양한 클라이언트 애플리케이션에서 사용할 수 있습니다.\n",
      "*   언어 모델의 성능을 모니터링하고 최적화할 수 있습니다.\n",
      "\n",
      "LangServe는 다음과 같은 다양한 시나리오에서 사용할 수 있습니다:\n",
      "\n",
      "*   챗봇 및 가상 에이전트 개발\n",
      "*   자연어 처리(NLP) 작업 자동화\n",
      "*   콘텐츠 생성 및 요약\n",
      "*   언어 번역 및 언어 모델 기반 애플리케이션 개발\n",
      "\n",
      "요약하면, LangServe는 대규모 언어 모델을 쉽게 배포하고 관리할 수 있도록 지원하는 강력한 라이브러리로서, 개발자가 언어 모델 기반 애플리케이션을 효율적으로 구축할 수 있도록 돕습니다.\n"
     ]
    }
   ],
   "source": [
    "try:    # llm 호출\n",
    "    response = llm.invoke(prompt_text) \n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03333b28",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM을 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93694e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='\\n    You are an expert in AI Expert. Answer the question. \\n    <Question>: {input}에 대해 쉽게 한글로 설명해주세요.\\n    ')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an expert in AI Expert. Answer the question. \n",
    "    <Question>: {input}에 대해 쉽게 한글로 설명해주세요.\n",
    "    \"\"\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5a86543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cea524",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM + OuterParser를 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a89111af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "output_parser = StrOutputParser()\n",
    "chain2 = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c723132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 방식과 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습하고, 주어진 문제에 대해 더 잘 해결할 수 있도록 모델을 개선하는 과정입니다.\n",
      "\n",
      "여기 간단한 학습 원리를 설명해 드리겠습니다:\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해, 우선 많은 데이터를 수집합니다. 이 데이터는 문제에 대한 다양한 사례를 포함해야 합니다.\n",
      "\n",
      "2. **모델 초기화**: 수집된 데이터를 바탕으로 모델을 초기화합니다. 모델은 문제의 유형에 따라 결정되며, 예를 들어 이미지 인식에는 합성곱 신경망(CNN), 자연어 처리에는 순환 신경망(RNN) 또는 트랜스포머 모델을 사용할 수 있습니다.\n",
      "\n",
      "3. **학습 과정**: 모델에 데이터를 입력하고, 모델이 예측한 결과와 실제 결과를 비교합니다. 이 비교를 통해 모델이 얼마나 잘못 예측했는지 계산합니다. 이 값은 '손실 함수(Loss Function)'로 표현됩니다.\n",
      "\n",
      "4. **역전파**: 손실 함수를 최소화하기 위해, 모델의 각 파라미터에 대해 손실 함수의 기울기를 계산합니다. 이 과정은 '역전파(Backpropagation)'라고 하며, 각 파라미터가 손실 함수에 미치는 영향을 파악하는 데 사용됩니다.\n",
      "\n",
      "5. **파라미터 업데이트**: 기울기 정보를 바탕으로 모델의 파라미터를 업데이트합니다. 이 과정은 '최적화 알고리즘'을 통해 수행되며, 예를 들어 경사 하강법(Gradient Descent)이나 Adam, RMSprop 등이 있습니다. 파라미터를 업데이트함으로써 모델의 예측 성능을 개선합니다.\n",
      "\n",
      "6. **반복 학습**: 3~5번의 과정을 여러 번 반복합니다. 반복할수록 모델은 학습 데이터에 대해 더 나은 예측을 할 수 있게 됩니다.\n",
      "\n",
      "7. **평가**: 학습된 모델의 성능을 평가합니다. 이를 위해 별도의 테스트 데이터를 사용하며, 모델의 성능 지표(예: 정확도, 정밀도, 재현율 등)를 확인합니다.\n",
      "\n",
      "8. **튜닝 및 배포**: 모델의 성능이 만족할 만한 수준에 도달하면, 실제 문제 해결을 위해 배포합니다. 필요하다면 하이퍼파라미터 튜닝 등을 통해 모델의 성능을 추가적으로 개선할 수 있습니다.\n",
      "\n",
      "이렇게 인공지능 모델은 데이터를 통해 학습하고, 스스로를 개선해 나가는 것입니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "    print(type(result))\n",
    "    print(result.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb609ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "LangChain은 인공지능(AI) 기술을 활용하여 자연어 처리(NLP) 및 대화형 AI 솔루션을 제공하는 회사입니다. LangChain의 제품은 주로 자연어 이해, 대화 관리, 그리고 콘텐츠 생성과 관련된 AI 기술들을 포함하고 있습니다. 아래는 LangChain의 주요 제품 및 기능에 대한 설명입니다.\n",
      "\n",
      "1. **LangChain 플랫폼**: LangChain의 핵심 플랫폼은 개발자가 대화형 AI 애플리케이션을 쉽게 구축할 수 있도록 설계되었습니다. 이 플랫폼은 자연어 처리, 기계 학습, 그리고 대화 흐름 관리 기능을 통합하여 제공하며, 개발자가 맞춤형 대화 경험을 만들 수 있도록 지원합니다.\n",
      "\n",
      "2. **대화형 AI 솔루션**: LangChain은 다양한 산업 분야에서 활용할 수 있는 대화형 AI 솔루션을 제공합니다. 이 솔루션은 고객 서비스, 판매 지원, 정보 제공 등 다양한 목적으로 사용될 수 있으며, 자연어 이해를 기반으로 한 정확한 답변 제공과 사용자 맞춤형 상호작용을 가능하게 합니다.\n",
      "\n",
      "3. **자연어 처리(NLP) 도구**: LangChain은 자연어 처리를 위한 다양한 도구와 라이브러리를 제공합니다. 이러한 도구들은 텍스트 분석, 감정 분석, 개체 인식 등과 같은 기능을 포함하며, 개발자가 텍스트 데이터를 효과적으로 처리하고 이해할 수 있도록 돕습니다.\n",
      "\n",
      "4. **콘텐츠 생성 도구**: LangChain의 콘텐츠 생성 도구를 사용하면 자동으로 텍스트 콘텐츠를 생성할 수 있습니다. 이 도구는 블로그 포스트, 제품 설명, 소셜 미디어 콘텐츠 등 다양한 유형의 콘텐츠를 자동으로 작성하는 데 사용될 수 있습니다.\n",
      "\n",
      "5. **챗봇 및 가상 에이전트**: LangChain은 챗봇 및 가상 에이전트 개발을 위한 솔루션도 제공합니다. 이러한 챗봇과 가상 에이전트는 웹사이트, 모바일 앱, 메시징 플랫폼 등 다양한 채널에서 사용자들과 상호작용하며, 고객 지원, 정보 제공, 거래 처리 등의 작업을 수행할 수 있습니다.\n",
      "\n",
      "LangChain의 제품들은 기업이 고객과의 상호작용을 개선하고, 내부 프로세스를 자동화하며, 콘텐츠 생성 효율성을 높이는 데 기여할 수 있습니다. 이러한 기술들은 다양한 산업 분야에서 활용되며, 기업들이 디지털 전환을 가속화하고 혁신적인 고객 경험을 제공하도록 돕습니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain2.invoke({\"input\": \"LangChain의 Product(제품)에는 어떤 것들이 있나요?\"})\n",
    "    print(type(result))\n",
    "    print(result) # output parser라서 스트링으로 바로 나옴\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee094ccd",
   "metadata": {},
   "source": [
    "### Runnable의 stream() 함수 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "867594c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리를 쉽게 설명해 드리겠습니다.\n",
      "\n",
      "**인공지능 모델의 학습 원리**\n",
      "\n",
      "인공지능 모델의 학습은 크게 세 가지 단계로 이루어져 있습니다: 데이터 수집, 모델 훈련, 모델 평가.\n",
      "\n",
      "### 1. 데이터 수집\n",
      "\n",
      "인공지능 모델을 학습시키기 위해서는 많은 양의 데이터가 필요합니다. 이 데이터는 문제에 따라 달라지며, 이미지, 텍스트, 오디오 등 다양한 형태일 수 있습니다. 예를 들어, 고양이와 개를 구분하는 모델을 만든다고 가정해 봅시다. 이 경우, 수많은 고양이와 개의 이미지 데이터를 수집해야 합니다.\n",
      "\n",
      "### 2. 모델 훈련\n",
      "\n",
      "수집된 데이터를 바탕으로 모델을 훈련시킵니다. 이 과정에서는 모델이 데이터를 분석하고 학습할 수 있도록 알고리즘을 적용합니다. 대표적인 알고리즘에는 신경망(SNN), 결정 트리, 서포트 벡터 머신(SVM) 등이 있습니다. 이 중에서 신경망은 여러 층으로 구성된 노드들을 통해 복잡한 패턴을 학습할 수 있어 널리 사용됩니다.\n",
      "\n",
      "훈련 과정에서는 모델이 입력 데이터로부터 특징을 추출하고, 이를 바탕으로 예측을 수행합니다. 이때 예측 결과와 실제 값 사이의 차이를 손실 함수(Loss Function)로 계산합니다. 손실 함수는 모델의 성능을 평가하는 지표로 사용되며, 모델의 가중치를 업데이트하는 기준이 됩니다.\n",
      "\n",
      "모델은 예측 결과와 실제 값의 차이가 최소화되도록 가중치를 조정하면서 학습합니다. 이 과정을 반복적으로 수행하면서 모델의 성능이 개선됩니다.\n",
      "\n",
      "### 3. 모델 평가\n",
      "\n",
      "모델 훈련이 완료되면, 모델의 성능을 평가합니다. 이를 위해 별도의 테스트 데이터를 사용합니다. 테스트 데이터에 모델을 적용하여 예측 결과를 도출하고, 이를 실제 값과 비교하여 모델의 성능을 평가합니다.\n",
      "\n",
      "성능 평가 지표로는 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1 스코어 등이 있습니다. 이러한 지표를 바탕으로 모델의 성능을 분석하고, 필요에 따라 모델을 수정하거나 추가적인 학습을 진행합니다.\n",
      "\n",
      "**결론**\n",
      "\n",
      "인공지능 모델의 학습 원리는 데이터 수집, 모델 훈련, 모델 평가의 세 가지 단계로 요약할 수 있습니다. 모델은 데이터를 통해 학습하고, 예측 성능을 개선해 나갑니다. 이를 통해 인공지능 모델은 다양한 분야에서 활용될 수 있습니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "try:\n",
    "    answer = chain2.stream({\"input\": \"인공지능 모델의 학습 원리를 자세하게 설명해 주세요.\"})\n",
    "\n",
    "    # 스트리밍 출력\n",
    "    # print(answer)\n",
    "\n",
    "    for token in answer:\n",
    "        # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "        print(token, end=\"\", flush=True)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a1e5ef",
   "metadata": {},
   "source": [
    "### Multi Chain\n",
    "* 첫번째 Chain의 출력이, 두번째 Chain의 입력이 된다.\n",
    "* 두개의 Chain과 Prompt + OutputParser를 LCEL로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c922be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추전한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 줄거리를 3문장으로 요약해 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a66bab6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**영화: '그것만이 내 전재산'**\n",
      "\n",
      "이 영화는 20년 동안 홀아버지와 단둘이 살아온 소녀가 아버지의 사업 실패로 위기를 맞게 되면서 시작합니다. 소녀는 아버지를 대신해 사업에 나서게 되지만, 이 과정은 쉽지 않습니다. 소녀는 포기하지 않고 아버지를 대신해 사업을 운영하며, 다양한 어려움을 극복해 나갑니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "try:\n",
    "    chain2 = (\n",
    "        {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "        | prompt2\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "    response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ed46dc",
   "metadata": {},
   "source": [
    "### PromptTemplate 여러개 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f97c8658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "ChatGPT는 대규모 언어 데이터셋을 기반으로 하는 트랜스포머 아키텍처를 사용하여 학습됩니다. 이 모델은 주어진 문맥에서 다음에 나타날 단어를 예측하도록 훈련되며, 이를 통해 자연스러운 대화 흐름을 생성할 수 있습니다. 학습 과정에서 모델은 많은 양의 텍스트 데이터를 분석하고 패턴을 학습하여 대화에 적합한 응답을 생성합니다.\n",
      "\n",
      "ChatGPT 모델의 장점은 다음과 같습니다.\n",
      "\n",
      "* 자연스러운 대화 생성: ChatGPT는 매우 자연스럽고 유연한 대화 흐름을 생성할 수 있습니다.\n",
      "* 대규모 지식 기반: ChatGPT는 대규모 언어 데이터셋을 기반으로 학습되어 다양한 주제에 대한 지식을 가지고 있습니다.\n",
      "* 높은 활용성: ChatGPT는 챗봇, 언어 번역, 텍스트 요약 등 다양한 자연어 처리 작업에 활용될 수 있습니다.\n",
      "\n",
      "ChatGPT 모델과 비슷한 AI 모델은 다음과 있습니다.\n",
      "\n",
      "* LLaMA\n",
      "* PaLM\n",
      "* BERT\n",
      "* RoBERTa\n",
      "* XLNet\n",
      "\n",
      "이러한 모델들은 대부분 트랜스포머 아키텍처를 기반으로 하며, 자연어 처리 작업에 활용됩니다.\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 요약해서 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"영어\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"영어\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed578600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 2 문장으로 요약해서 한국어로 답변해 주세요.', 'Gemma 모델의 학습 원리를 3 문장으로 요약해서 한국어로 답변해 주세요.', 'llama-4 모델의 학습 원리를 4 문장으로 요약해서 한국어로 답변해 주세요.']\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 요약해서 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 2},\n",
    "    {\"model_name\": \"Gemma\", \"count\": 3},\n",
    "    {\"model_name\": \"llama-4\", \"count\": 4}\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions] # q가 dict 타입 **의 의미는 dict가 넘어갈 때 사용\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b289869a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 모델은 대규모 데이터 세트에 대해 훈련된 생성형 언어 모델로서, 주어진 입력에 대해 다음에 올 가능성이 높은 단어를 예측하도록 학습합니다. GPT-4는 이전 모델인 GPT-3와 마찬가지로 트랜스포머 아키텍처를 기반으로 하며, 수십억 개의 매개변수를 조정하여 자연어 처리 작업에서 뛰어난 성능을 발휘하도록 학습되었습니다.\n",
      "Gemma 모델은 주어진 문맥을 기반으로 학습을 진행하며 자연어 처리 작업을 수행합니다. 학습 과정에서 Gemma는 주어진 문맥 안에서 단어 또는 토큰 간의 관계를 학습하고 패턴을 식별합니다. Gemma는 대규모 언어 모델로서 효율적인 아키텍처와 훈련 데이터를 사용하여 학습되며, 다양한 자연어 처리 작업에 활용할 수 있습니다.\n",
      "llama-4 모델은 메타에서 개발한 대규모 언어 모델입니다. 이 모델은 텍스트 데이터를 학습하여 자연어 처리 능력을 키우는데, 인터넷에서 수집한 방대한 텍스트 데이터를 기반으로 학습합니다. 학습 과정에서 모델은 주변 단어의 맥락을 고려하여 다음 단어를 예측하는 방식으로 훈련되며, 이를 통해 언어의 패턴과 구조를 학습합니다. 이 과정을 통해 모델은 다양한 자연어 처리 작업에 활용될 수 있는 강력한 언어 이해 능력을 습득하게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    response = llm.invoke(prompt)\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf95a3",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePrompt Template 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df10a7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "Here are the key points:\n",
      "\n",
      "* **Definition**: 딥러닝은 인공신경망을 기반으로 하는 기계학습의 한 분야입니다. \n",
      "* **Inspiration**: 인간의 뇌 구조를 모방하여 만들어진 알고리즘으로, 복잡한 데이터로부터 패턴을 학습하고 예측하는 데 사용됩니다. \n",
      "* **Applications**: 이미지 인식, 음성 인식, 자연어 처리, 자율 주행 자동차 등 다양한 분야에서 활용되고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"당신은 {topic} 전문가 입니다. 명확하고 자세하게 설명해 주세요.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"딥러닝은 무엇인가요?\")\n",
    "\n",
    "# LLM 호출\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc32518",
   "metadata": {},
   "source": [
    "### FewShotPromptTemlate\n",
    "* 예시를 제공하는 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2f50dfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 태양계의 행성\n",
      "1. **수성**: 태양과 가장 가까운 행성으로, 매우 작고 온도가 극심하게 변합니다.\n",
      "2. **금성**: 두꺼운 대기로 인해 온실 효과가 심해 매우 뜨겁습니다.\n",
      "3. **지구**: 생명체가 존재하는 유일한 행성입니다.\n",
      "4. **화성**: 붉은 행성으로, 과거에는 물이 존재했을 것으로 추정됩니다.\n",
      "5. **목성**: 태양계에서 가장 큰 행성으로, 가스 행성입니다.\n",
      "6. **토성**: 아름다운 고리를 가진 가스 행성입니다.\n",
      "7. **천왕성**: 자전축이 기울어져 있어 극단적인 계절 변화를 겪습니다.\n",
      "8. **해왕성**: 태양계에서 가장 먼 행성으로, 강한 바람이 불어오는 가스 행성입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "model = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "chain = final_prompt | model\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"태양계의 행성들을 간략히 정리해 주세요.\"})\n",
    "#result = chain.invoke({\"input\": \"양자 얽힘이 무엇인가요?\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06b41a",
   "metadata": {},
   "source": [
    "### PartialPrompt Template\n",
    "* 프롬프트의 입력값에 동적인 함수 호출 이나 외부 API를 호출한 동적인 값을 대입할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d397043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 프롬프트: 여름에 일어나는 대표적인 지구과학 현상은 태풍 발생입니다.\n",
      "🔹 모델 응답: 태풍은 열대 지방의 바다에서 발생하는 강력한 폭풍우입니다. 따뜻한 바닷물의 수온이 상승하면서 상승 기류가 발생하고, 이로 인해 저기압이 형성됩니다. 저기압이 강화되면서 태풍이 발생하고, 강한 바람과 많은 비를 동반합니다.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "    \n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# 프롬프트 템플릿 정의 (부분 변수 적용)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}에 일어나는 대표적인 지구과학 현상은 {phenomenon}입니다.\",\n",
    "    input_variables=[\"phenomenon\"],  # 사용자 입력 필요\n",
    "    partial_variables={\"season\": get_current_season()}  # 동적으로 계절 값 할당\n",
    ")\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# 특정 계절의 현상 질의\n",
    "query = prompt.format(phenomenon=\"태풍 발생\")  # '태풍 발생'은 여름과 관련됨\n",
    "result = model.invoke(query)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"🔹 프롬프트: {query}\")\n",
    "print(f\"🔹 모델 응답: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b9cc7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 프롬프트: 현재 1달러 = 1374.55원 기준으로 환율 정보를 알려드립니다. 현재 환율을 기준으로 한국 경제에 미치는 영향 및 향후에 환율의 예상값에 대한 분석을 제공해 주세요.\n",
      "🔹 모델 응답: ## 현재 환율: 1달러 = 1374.55원\n",
      "\n",
      "### 한국 경제에 미치는 영향\n",
      "\n",
      "1. **수출 증가**: 높은 환율은 한국의 수출을 촉진할 수 있습니다. 수출 상품의 가격이 낮아져서 해외 시장에서 경쟁력이 증가하기 때문입니다. 이는 자동차, 반도체, 철강 등 주요 수출 산업에 긍정적인 영향을 미칠 수 있습니다.\n",
      "\n",
      "2. **수입 비용 증가**: 높은 환율은 수입 상품의 가격을 상승시켜 국내 물가 상승을 초래할 수 있습니다. 원유, 원자재, 전자제품 등 수입에 의존하는 산업의 비용 부담이 증가합니다.\n",
      "\n",
      "3. **물가 상승**: 수입 비용 증가로 인해 국내 물가가 상승할 수 있습니다. 이는 소비자들의 구매력을 감소시키고, 전반적인 경제 성장에 부정적인 영향을 미칠 수 있습니다.\n",
      "\n",
      "4. **외국인 투자**: 높은 환율은 외국인 투자자들에게 한국 시장에 대한 투자 매력을 감소시킬 수 있습니다. 이는 주식 시장 및 부동산 시장에 영향을 줄 수 있습니다.\n",
      "\n",
      "### 향후 환율 예상\n",
      "\n",
      "1. **글로벌 경제 상황**: 미국의 경제 상황, 금리 변동, 글로벌 무역 긴장 등 다양한 글로벌 경제 요인들이 환율에 영향을 미칩니다. 미국의 강한 경제 성장과 금리 인상은 달러 강세를 유지할 수 있습니다.\n",
      "\n",
      "2. **한국 경제 상황**: 한국의 경제 성장률, 물가 상승률, 무역 수지 등도 환율에 영향을 미칩니다. 한국 경제의 견조한 성장과 안정적인 물가가 환율 하락 요인으로 작용할 수 있습니다.\n",
      "\n",
      "3. **정책적 요인**: 한국은행과 정부의 경제 정책, 외환 시장 개입 등도 환율 변동에 영향을 미칩니다. 외환 시장에서의 개입이 환율의 변동성을 줄이는 역할을 할 수 있습니다.\n",
      "\n",
      "4. **국제 유가**: 국제 유가의 변동도 환율에 영향을 미칩니다. 유가 상승은 수입 비용 증가로 이어져 환율 상승 압력을 가중시킬 수 있습니다.\n",
      "\n",
      "### 예상 환율\n",
      "\n",
      "향후 환율의 예상은 매우 불확실하며, 다양한 변수에 따라 변동할 수 있습니다. 하지만, 전문가들은 미국의 경제 상황과 금리 정책, 한국의 경제 성장과 물가 안정, 글로벌 무역 상황 등을 고려하여 환율이 단기적으로는 1350원~1450원 범위 내에서 변동할 가능성이 있다고 예측합니다.\n",
      "\n",
      "장기적으로는 글로벌 경제의 회복, 무역 긴장 완화, 한국의 경제 성장 지속 등에 따라 환율이 안정화되고 하향세를 보일 가능성도 있습니다. 하지만, 이러한 예측은 불확실성이 크므로, 지속적인 모니터링이 필요합니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 실시간 환율을 가져오는 함수\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1달러 = {data['rates']['KRW']}원\"\n",
    "\n",
    "# {info} 변수에 API에서 받은 환율 정보를 동적으로 반영\n",
    "prompt = PromptTemplate(\n",
    "    template=\"현재 {info} 기준으로 환율 정보를 알려드립니다. 현재 환율을 기준으로 한국 경제에 미치는 영향 및 향후에 환율의 예상값에 대한 분석을 제공해 주세요.\",\n",
    "    input_variables=[],  # 사용자 입력 없음\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # API에서 가져온 데이터 자동 반영\n",
    ")\n",
    "\n",
    "# LLM 모델 설정 (GPT-4o-mini 사용)\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# 모델에 프롬프트 전달 및 응답 받기\n",
    "response = model.invoke(prompt.format())\n",
    "\n",
    "# 결과 출력\n",
    "print(\"🔹 프롬프트:\", prompt.format())\n",
    "print(\"🔹 모델 응답:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
