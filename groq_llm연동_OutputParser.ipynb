{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86fe129c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af9652b",
   "metadata": {},
   "source": [
    "### CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15965d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'format_instructions': 'Your response should be a list of comma separated '\n",
      "                        'values, eg: `foo, bar, baz` or `foo,bar,baz`'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "# ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ ê°€ì ¸ì˜¤ê¸°\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "pprint(prompt.partial_variables) # ì¶œë ¥ í˜•ì‹ ì§€ì¹¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c304314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI ê´€ë ¨ ê¸°ìˆ  ëª©ë¡:\n",
      "['Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Computer Vision', 'Robotics']\n",
      " './data/ai_technologies.csv' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# OpenAI ëª¨ë¸ ì„¤ì •\n",
    "# model = ChatOpenAI(temperature=0)\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸, ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ì—¬ ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# \"AI ê´€ë ¨ ê¸°ìˆ \"ì— ëŒ€í•œ ì²´ì¸ í˜¸ì¶œ ì‹¤í–‰\n",
    "result = chain.invoke({\"subject\": \"AI ê´€ë ¨ ê¸°ìˆ \"})\n",
    "\n",
    "# ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥\n",
    "print(\" AI ê´€ë ¨ ê¸°ìˆ  ëª©ë¡:\")\n",
    "print(result)\n",
    "\n",
    "# ê²°ê³¼ í™œìš© ì˜ˆì‹œ: CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "csv_filename = \"./data/ai_technologies.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"AI ê¸°ìˆ \"])  # í—¤ë” ì¶”ê°€\n",
    "    for item in result:\n",
    "        writer.writerow([item])\n",
    "\n",
    "print(f\" '{csv_filename}' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd44f6",
   "metadata": {},
   "source": [
    "### JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1d0faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] input_types={} partial_variables={'format_instructions': 'Return a JSON object.'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê³¼í•™ ë¶„ì•¼ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ ì²´ê³„ì ì´ê³  ê°„ê²°í•œ ë‹µë³€ì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'question'], input_types={}, partial_variables={}, template='#Format: {format_instructions}\\n\\n#Question: {question}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "# JSON ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ê³¼í•™ ë¶„ì•¼ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ ì²´ê³„ì ì´ê³  ê°„ê²°í•œ ë‹µë³€ì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.\"),\n",
    "        (\"user\", \"#Format: {format_instructions}\\n\\n#Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# JSON ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ì„ í”„ë¡¬í”„íŠ¸ì— ì ìš©\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9627b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"mission_name\": \"ë‰´í˜¸ë¼ì´ì¦ŒìŠ¤\",\n",
      "        \"goal\": \"ëª…ì™•ì„± íƒì‚¬\",\n",
      "        \"agency\": \"NASA\"\n",
      "    },\n",
      "    {\n",
      "        \"mission_name\": \"ì¹´ì‹œë‹ˆ-í˜¸ì´ê²ìŠ¤\",\n",
      "        \"goal\": \"í† ì„±ì˜ ìœ„ì„± íƒ€ì´íƒ„ íƒì‚¬\",\n",
      "        \"agency\": \"NASA, ESA, ì´íƒˆë¦¬ì•„ ìš°ì£¼êµ­\"\n",
      "    },\n",
      "    {\n",
      "        \"mission_name\": \"ì°½ì–´ 4í˜¸\",\n",
      "        \"goal\": \"ë‹¬ì˜ ë’·ë©´ íƒì‚¬\",\n",
      "        \"agency\": \"ì¤‘êµ­ ìš°ì£¼êµ­\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# OpenAI ëª¨ë¸ ì„¤ì •\n",
    "# model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸, ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ëŠ” ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ì§ˆë¬¸ ì„¤ì • (ìš°ì£¼ íƒì‚¬ ê´€ë ¨ ì§ˆë¬¸)\n",
    "question = \"ìµœê·¼ 10ë…„ê°„ ì§„í–‰ëœ ì£¼ìš” ìš°ì£¼ íƒì‚¬ ë¯¸ì…˜ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. \\\n",
    "ê° ë¯¸ì…˜ì˜ ì´ë¦„ì€ `mission_name`ì—, ëª©í‘œëŠ” `goal`ì—, ì£¼ê´€ ê¸°ê´€ì€ `agency`ì— ë‹´ì•„ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰ ë° JSON ì‘ë‹µ ë°›ê¸°\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "# JSON ë°ì´í„° ì¶œë ¥\n",
    "print(json.dumps(response, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9d4a2c",
   "metadata": {},
   "source": [
    "### PandasDataFrameOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c96c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from typing import Any, Dict\n",
    "import pandas as pd\n",
    "from langchain.output_parsers import PandasDataFrameOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Titanic ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# Pandas DataFrame Output Parser ì„¤ì •\n",
    "parser = PandasDataFrameOutputParser(dataframe=df)\n",
    "# print(parser)\n",
    "\n",
    "# í˜•ì‹ ì§€ì¹¨ ì¶œë ¥\n",
    "format_instructions = parser.get_format_instructions()\n",
    "# print(\"Format Instructions: \\n\", format_instructions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a237af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived, Pclass, Name, Sex, Age, Siblings/Spouses Aboard, Parents/Children Aboard, Fare\n"
     ]
    }
   ],
   "source": [
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "# model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\" \n",
    "    You are a helpful assistant that interacts with a Pandas DataFrame.\n",
    "    The DataFrame contains the following columns: {columns}.\n",
    "    \n",
    "    Your task is to answer the user's query by generating a command in the following format:\n",
    "    {format_instructions}\n",
    "    \n",
    "    User Query: {query}    \n",
    "    \"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": format_instructions,\n",
    "        \"columns\": \", \".join(df.columns)\n",
    "    },\n",
    ")\n",
    "print(prompt.partial_variables['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3c53c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name ì»¬ëŸ¼ ì¶œë ¥\n",
      "ì˜¤ë¥˜ ë°œìƒ: Request 'The command in the required format is: \n",
      "column:Name. \n",
      "\n",
      "This will display the 'Name' column of the DataFrame. \n",
      "\n",
      "If you would like to see a specific row or a range of rows, you can modify it as follows:\n",
      "- To get a specific row: row:1[Name]\n",
      "- To get a column for specific rows: column:Name[1,3,5]\n",
      "- To get a column for a range of rows: column:Name[1..3] \n",
      "- To perform an operation: mean:Name is not valid since mean is not a string column, but  \"mean:Age\" or  \"sum:Fare\" could be used.' is not correctly formatted.                     Please refer to the format instructions.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ëª¨ë¸ ì‘ë‹µ ë°›ê¸°\n",
    "try:\n",
    "    # **Name ì—´ì„ í‘œì‹œí•˜ì‹­ì‹œì˜¤.**\n",
    "    print('Name ì»¬ëŸ¼ ì¶œë ¥')\n",
    "    df_query = \"Show the Name column\"\n",
    "\n",
    "    parser_output = chain.invoke({\"query\": df_query})\n",
    "    print(type(parser_output))\n",
    "    print(parser_output)\n",
    "\n",
    "    # **ì²«ë²ˆì§¸ í–‰ì„ í‘œì‹œí•˜ì‹­ì‹œì˜¤.**\n",
    "    print('ì²«ë²ˆì§¸ í–‰ ì¶œë ¥')\n",
    "    df_query2 = \"Show first row\"\n",
    "\n",
    "    parser_output2 = chain.invoke({\"query\": df_query2})\n",
    "    print(parser_output2)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b877d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] input_types={} partial_variables={'format_instructions': 'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"data\": string  // A list of dictionaries representing table rows.\\n}\\n```'} template='\\n    You are an AI assistant that generates tabular data. \\n    You must return the data in JSON format that follows this schema:\\n\\n    {format_instructions}\\n\\n    **User Query:**\\n    {query}\\n    '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "# model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ì •ì˜ {data : [{},{},{}] }\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"data\", description=\"A list of dictionaries representing table rows.\"),\n",
    "]\n",
    "\n",
    "# Output Parser ì„¤ì •\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an AI assistant that generates tabular data. \n",
    "    You must return the data in JSON format that follows this schema:\n",
    "    \n",
    "    {format_instructions}\n",
    "        \n",
    "    **User Query:**\n",
    "    {query}\n",
    "    \"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54147d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ ìƒì„± (í”„ë¡¬í”„íŠ¸ â†’ ëª¨ë¸ â†’ OutputParser)\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ì‹¤í–‰ í•¨ìˆ˜\n",
    "def generate_dataframe(user_query):\n",
    "    try:\n",
    "        # ëª¨ë¸ í˜¸ì¶œ\n",
    "        json_response = chain.invoke({\"query\": user_query})\n",
    "        print(json_response)\n",
    "        \n",
    "        # ëª¨ë¸ì´ ë°˜í™˜í•œ JSONì„ Pandas DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "        df = pd.DataFrame(json_response[\"data\"])\n",
    "\n",
    "        # ê²°ê³¼ ì¶œë ¥\n",
    "        print(\"\\nğŸ”¹ Generated DataFrame:\\n\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "758f58e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024ë…„ í•˜ë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±\n",
      "{'data': [{'District': 'Gangnam-gu', 'Average Price (KRW)': 1200000000, 'Number of Transactions': 150, 'Year-over-Year Change (%)': 10.2}, {'District': 'Gangdong-gu', 'Average Price (KRW)': 900000000, 'Number of Transactions': 120, 'Year-over-Year Change (%)': 8.5}, {'District': 'Gwangjin-gu', 'Average Price (KRW)': 1000000000, 'Number of Transactions': 180, 'Year-over-Year Change (%)': 12.1}, {'District': 'Dongdaemun-gu', 'Average Price (KRW)': 800000000, 'Number of Transactions': 100, 'Year-over-Year Change (%)': 6.8}, {'District': 'Dongjak-gu', 'Average Price (KRW)': 950000000, 'Number of Transactions': 140, 'Year-over-Year Change (%)': 9.2}, {'District': 'Eunpyeong-gu', 'Average Price (KRW)': 700000000, 'Number of Transactions': 80, 'Year-over-Year Change (%)': 5.5}, {'District': 'Geumcheon-gu', 'Average Price (KRW)': 600000000, 'Number of Transactions': 60, 'Year-over-Year Change (%)': 4.2}, {'District': 'Gu-ro-gu', 'Average Price (KRW)': 850000000, 'Number of Transactions': 110, 'Year-over-Year Change (%)': 7.5}, {'District': 'Gwanak-gu', 'Average Price (KRW)': 650000000, 'Number of Transactions': 90, 'Year-over-Year Change (%)': 5.8}, {'District': 'Gwangju', 'Average Price (KRW)': 750000000, 'Number of Transactions': 130, 'Year-over-Year Change (%)': 8.1}, {'District': 'Jongno-gu', 'Average Price (KRW)': 1400000000, 'Number of Transactions': 160, 'Year-over-Year Change (%)': 11.5}, {'District': 'Mapo-gu', 'Average Price (KRW)': 1100000000, 'Number of Transactions': 170, 'Year-over-Year Change (%)': 10.8}, {'District': 'Nowon-gu', 'Average Price (KRW)': 720000000, 'Number of Transactions': 85, 'Year-over-Year Change (%)': 6.2}, {'District': 'Oeuljeon-gu', 'Average Price (KRW)': 820000000, 'Number of Transactions': 105, 'Year-over-Year Change (%)': 7.1}, {'District': 'Seodaemun-gu', 'Average Price (KRW)': 900000000, 'Number of Transactions': 125, 'Year-over-Year Change (%)': 8.8}, {'District': 'Seongbuk-gu', 'Average Price (KRW)': 950000000, 'Number of Transactions': 145, 'Year-over-Year Change (%)': 9.5}, {'District': 'Songpa-gu', 'Average Price (KRW)': 1300000000, 'Number of Transactions': 190, 'Year-over-Year Change (%)': 11.8}, {'District': 'Yangcheon-gu', 'Average Price (KRW)': 780000000, 'Number of Transactions': 95, 'Year-over-Year Change (%)': 6.5}, {'District': 'Yangpyeong-gu', 'Average Price (KRW)': 680000000, 'Number of Transactions': 75, 'Year-over-Year Change (%)': 5.1}, {'District': 'Yongsan-gu', 'Average Price (KRW)': 1500000000, 'Number of Transactions': 200, 'Year-over-Year Change (%)': 12.5}, {'District': 'Yonsei-ro', 'Average Price (KRW)': 1600000000, 'Number of Transactions': 220, 'Year-over-Year Change (%)': 13.2}]}\n",
      "\n",
      "ğŸ”¹ Generated DataFrame:\n",
      "\n",
      "(21, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District</th>\n",
       "      <th>Average Price (KRW)</th>\n",
       "      <th>Number of Transactions</th>\n",
       "      <th>Year-over-Year Change (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gangnam-gu</td>\n",
       "      <td>1200000000</td>\n",
       "      <td>150</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gangdong-gu</td>\n",
       "      <td>900000000</td>\n",
       "      <td>120</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gwangjin-gu</td>\n",
       "      <td>1000000000</td>\n",
       "      <td>180</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dongdaemun-gu</td>\n",
       "      <td>800000000</td>\n",
       "      <td>100</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dongjak-gu</td>\n",
       "      <td>950000000</td>\n",
       "      <td>140</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Eunpyeong-gu</td>\n",
       "      <td>700000000</td>\n",
       "      <td>80</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Geumcheon-gu</td>\n",
       "      <td>600000000</td>\n",
       "      <td>60</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gu-ro-gu</td>\n",
       "      <td>850000000</td>\n",
       "      <td>110</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gwanak-gu</td>\n",
       "      <td>650000000</td>\n",
       "      <td>90</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gwangju</td>\n",
       "      <td>750000000</td>\n",
       "      <td>130</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jongno-gu</td>\n",
       "      <td>1400000000</td>\n",
       "      <td>160</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mapo-gu</td>\n",
       "      <td>1100000000</td>\n",
       "      <td>170</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nowon-gu</td>\n",
       "      <td>720000000</td>\n",
       "      <td>85</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Oeuljeon-gu</td>\n",
       "      <td>820000000</td>\n",
       "      <td>105</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Seodaemun-gu</td>\n",
       "      <td>900000000</td>\n",
       "      <td>125</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Seongbuk-gu</td>\n",
       "      <td>950000000</td>\n",
       "      <td>145</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Songpa-gu</td>\n",
       "      <td>1300000000</td>\n",
       "      <td>190</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Yangcheon-gu</td>\n",
       "      <td>780000000</td>\n",
       "      <td>95</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Yangpyeong-gu</td>\n",
       "      <td>680000000</td>\n",
       "      <td>75</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Yongsan-gu</td>\n",
       "      <td>1500000000</td>\n",
       "      <td>200</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Yonsei-ro</td>\n",
       "      <td>1600000000</td>\n",
       "      <td>220</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         District  Average Price (KRW)  Number of Transactions  \\\n",
       "0      Gangnam-gu           1200000000                     150   \n",
       "1     Gangdong-gu            900000000                     120   \n",
       "2     Gwangjin-gu           1000000000                     180   \n",
       "3   Dongdaemun-gu            800000000                     100   \n",
       "4      Dongjak-gu            950000000                     140   \n",
       "5    Eunpyeong-gu            700000000                      80   \n",
       "6    Geumcheon-gu            600000000                      60   \n",
       "7        Gu-ro-gu            850000000                     110   \n",
       "8       Gwanak-gu            650000000                      90   \n",
       "9         Gwangju            750000000                     130   \n",
       "10      Jongno-gu           1400000000                     160   \n",
       "11        Mapo-gu           1100000000                     170   \n",
       "12       Nowon-gu            720000000                      85   \n",
       "13    Oeuljeon-gu            820000000                     105   \n",
       "14   Seodaemun-gu            900000000                     125   \n",
       "15    Seongbuk-gu            950000000                     145   \n",
       "16      Songpa-gu           1300000000                     190   \n",
       "17   Yangcheon-gu            780000000                      95   \n",
       "18  Yangpyeong-gu            680000000                      75   \n",
       "19     Yongsan-gu           1500000000                     200   \n",
       "20      Yonsei-ro           1600000000                     220   \n",
       "\n",
       "    Year-over-Year Change (%)  \n",
       "0                        10.2  \n",
       "1                         8.5  \n",
       "2                        12.1  \n",
       "3                         6.8  \n",
       "4                         9.2  \n",
       "5                         5.5  \n",
       "6                         4.2  \n",
       "7                         7.5  \n",
       "8                         5.8  \n",
       "9                         8.1  \n",
       "10                       11.5  \n",
       "11                       10.8  \n",
       "12                        6.2  \n",
       "13                        7.1  \n",
       "14                        8.8  \n",
       "15                        9.5  \n",
       "16                       11.8  \n",
       "17                        6.5  \n",
       "18                        5.1  \n",
       "19                       12.5  \n",
       "20                       13.2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [ì˜ˆì œ 1] 2024ë…„ ìƒë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±\n",
    "print('2024ë…„ í•˜ë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±')\n",
    "df_seoul_housing = generate_dataframe(\n",
    "    \"Create a dataset of the average apartment sale prices in Seoul for the second half of 2024 with columns: District (êµ¬), Average Price (in KRW), Number of Transactions, and Year-over-Year Change (%).\"\n",
    ")\n",
    "print(df_seoul_housing.shape)\n",
    "df_seoul_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "601d93d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°\n",
      "{'data': [{'Station Name': 'Gangnam Station', 'Line Number': '2', 'Daily Passenger Volume': '146,321', 'Weekday vs Weekend Ratio': '1.23'}, {'Station Name': 'Hongdae Station', 'Line Number': '2', 'Daily Passenger Volume': '134,819', 'Weekday vs Weekend Ratio': '1.17'}, {'Station Name': 'Itaewon Station', 'Line Number': '4', 'Daily Passenger Volume': '123,456', 'Weekday vs Weekend Ratio': '1.05'}, {'Station Name': 'Yongsan Station', 'Line Number': '1, 4', 'Daily Passenger Volume': '114,285', 'Weekday vs Weekend Ratio': '1.22'}, {'Station Name': 'Jamsil Station', 'Line Number': '2, 8', 'Daily Passenger Volume': '107,692', 'Weekday vs Weekend Ratio': '1.11'}, {'Station Name': 'Bongeunsa Station', 'Line Number': '2', 'Daily Passenger Volume': '104,167', 'Weekday vs Weekend Ratio': '1.19'}, {'Station Name': 'Seoul Station', 'Line Number': '1, 4, Gyeongbu', 'Daily Passenger Volume': '98,654', 'Weekday vs Weekend Ratio': '1.25'}, {'Station Name': 'Dongdaemun History & Culture Park Station', 'Line Number': '2, 4, 5', 'Daily Passenger Volume': '94,286', 'Weekday vs Weekend Ratio': '1.08'}, {'Station Name': 'Myeong-dong Station', 'Line Number': '4', 'Daily Passenger Volume': '92,381', 'Weekday vs Weekend Ratio': '1.16'}, {'Station Name': 'Insadong Station', 'Line Number': '3', 'Daily Passenger Volume': '88,462', 'Weekday vs Weekend Ratio': '1.04'}]}\n",
      "\n",
      "ğŸ”¹ Generated DataFrame:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°')\n",
    "# [ì˜ˆì œ 2] 2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°\n",
    "df_seoul_subway = generate_dataframe(\n",
    "    \"Generate a dataset of the top 10 busiest subway stations in Seoul in 2024 with columns: Station Name, Line Number, Daily Passenger Volume, and Weekday vs Weekend Ratio.\"\n",
    ")\n",
    "if df_seoul_subway is not None:\n",
    "    #print(df_seoul_subway.shape)\n",
    "    df_seoul_subway.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c90b0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ 5ëŒ€ í¸ì˜ì  ë¸Œëœë“œë³„ 2024ë…„ ë§¤ì¶œ ë° ì í¬ ìˆ˜\n",
      "{'data': [{'Brand Name': 'CU', 'Number of Stores': 15432, 'Total Revenue': 11.5, 'Market Share': 27.3}, {'Brand Name': 'GS25', 'Number of Stores': 13345, 'Total Revenue': 9.8, 'Market Share': 23.5}, {'Brand Name': '7-Eleven', 'Number of Stores': 11256, 'Total Revenue': 8.2, 'Market Share': 20.2}, {'Brand Name': 'E-Mart24', 'Number of Stores': 9012, 'Total Revenue': 6.5, 'Market Share': 16.1}, {'Brand Name': 'Homeplus', 'Number of Stores': 7010, 'Total Revenue': 5.2, 'Market Share': 12.9}]}\n",
      "\n",
      "ğŸ”¹ Generated DataFrame:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Number of Stores</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Market Share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CU</td>\n",
       "      <td>15432</td>\n",
       "      <td>11.5</td>\n",
       "      <td>27.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GS25</td>\n",
       "      <td>13345</td>\n",
       "      <td>9.8</td>\n",
       "      <td>23.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7-Eleven</td>\n",
       "      <td>11256</td>\n",
       "      <td>8.2</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E-Mart24</td>\n",
       "      <td>9012</td>\n",
       "      <td>6.5</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homeplus</td>\n",
       "      <td>7010</td>\n",
       "      <td>5.2</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Brand Name  Number of Stores  Total Revenue  Market Share\n",
       "0         CU             15432           11.5          27.3\n",
       "1       GS25             13345            9.8          23.5\n",
       "2   7-Eleven             11256            8.2          20.2\n",
       "3   E-Mart24              9012            6.5          16.1\n",
       "4   Homeplus              7010            5.2          12.9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('í•œêµ­ 5ëŒ€ í¸ì˜ì  ë¸Œëœë“œë³„ 2024ë…„ ë§¤ì¶œ ë° ì í¬ ìˆ˜')\n",
    "# [ì˜ˆì œ 3] í•œêµ­ 5ëŒ€ í¸ì˜ì  ë¸Œëœë“œë³„ 2024ë…„ ë§¤ì¶œ ë° ì í¬ ìˆ˜\n",
    "df_korean_convenience_stores = generate_dataframe(\n",
    "    \"Create a dataset of the top 5 convenience store brands in Korea in 2024 with columns: Brand Name, Number of Stores, Total Revenue (in billion KRW), and Market Share (%).\"\n",
    ")\n",
    "df_korean_convenience_stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5da4b9",
   "metadata": {},
   "source": [
    "### PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a278db49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "#%pip install pydantic\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# .env íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24994dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] input_types={} partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"movie_title\": {\"description\": \"ì¶”ì²œ ì˜í™” ì œëª©\", \"title\": \"Movie Title\", \"type\": \"string\"}, \"reason\": {\"description\": \"ì¶”ì²œ ì´ìœ \", \"title\": \"Reason\", \"type\": \"string\"}, \"genre\": {\"description\": \"ì˜í™” ì¥ë¥´\", \"items\": {\"type\": \"string\"}, \"title\": \"Genre\", \"type\": \"array\"}, \"estimated_rating\": {\"description\": \"10ì  ë§Œì ì—ì„œ ì˜ˆìƒ í‰ì \", \"title\": \"Estimated Rating\", \"type\": \"number\"}}, \"required\": [\"movie_title\", \"reason\", \"genre\", \"estimated_rating\"]}\\n```'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'query'], input_types={}, partial_variables={}, template='\\në‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì˜í™”ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.\\nìš”ì²­: {query}\\n\\n{format_instructions}\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ì¶œë ¥ êµ¬ì¡°ë¥¼ ì •ì˜í•˜ëŠ” Pydantic ëª¨ë¸\n",
    "class MovieRecommendation(BaseModel): # BaseModel ìƒì†\n",
    "    movie_title: str = Field(description=\"ì¶”ì²œ ì˜í™” ì œëª©\")\n",
    "    reason: str = Field(description=\"ì¶”ì²œ ì´ìœ \")\n",
    "    genre: List[str] = Field(description=\"ì˜í™” ì¥ë¥´\")\n",
    "    estimated_rating: float = Field(description=\"10ì  ë§Œì ì—ì„œ ì˜ˆìƒ í‰ì \")\n",
    "    \n",
    "# Pydantic ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "parser = PydanticOutputParser(pydantic_object=MovieRecommendation)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "template = \"\"\"\n",
    "ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì˜í™”ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n",
    "ìš”ì²­: {query}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# íŒŒì„œì˜ ì§€ì‹œì‚¬í•­ì„ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…\n",
    "prompt = prompt.partial(\n",
    "    format_instructions=parser.get_format_instructions()\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f35e6fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶”ì²œ ì˜í™”: The Silence of the Lambs\n",
      "ì¶”ì²œ ì´ìœ : 1990ë…„ëŒ€ í´ë˜ì‹í•œ ëŠë‚Œì˜ ê³µí¬ ì˜í™”ë¡œ, ì˜¤ìŠ¤ì¹´ ìµœìš°ìˆ˜ ì‘í’ˆìƒì„ ìˆ˜ìƒí•œ ì‘í’ˆì…ë‹ˆë‹¤.\n",
      "ì¥ë¥´: ê³µí¬, ìŠ¤ë¦´ëŸ¬, ë¯¸ìŠ¤í„°ë¦¬\n",
      "ì˜ˆìƒ í‰ì : 9.5/10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "#model = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„± ë° ì‹¤í–‰\n",
    "query = \"1990ë…„ëŒ€ í´ë˜ì‹í•œ ëŠë‚Œì˜ ê³µí¬ ì˜í™” ì¶”ì²œí•´ì¤˜\"\n",
    "chain = prompt | model | parser\n",
    "output = chain.invoke({\"query\": query})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ì¶”ì²œ ì˜í™”: {output.movie_title}\")\n",
    "print(f\"ì¶”ì²œ ì´ìœ : {output.reason}\")\n",
    "print(f\"ì¥ë¥´: {', '.join(output.genre)}\")\n",
    "print(f\"ì˜ˆìƒ í‰ì : {output.estimated_rating}/10\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debd5fa3",
   "metadata": {},
   "source": [
    "### StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36d4beaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­:\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"rating\": string  // 5ì  ë§Œì ì—ì„œ ì˜ˆìƒ í‰ì \n",
      "\t\"pros\": string  // ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ì¥ì  3ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥\n",
      "\t\"cons\": string  // ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ë‹¨ì  3ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥\n",
      "\t\"summary\": string  // ë¦¬ë·°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# ì¶œë ¥ êµ¬ì¡° ì •ì˜ (í‰ì , ì¥ì , ë‹¨ì , ìš”ì•½)\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"rating\", description=\"5ì  ë§Œì ì—ì„œ ì˜ˆìƒ í‰ì \"),\n",
    "    ResponseSchema(name=\"pros\", description=\"ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ì¥ì  3ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥\"),\n",
    "    ResponseSchema(name=\"cons\", description=\"ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ë‹¨ì  3ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥\"),\n",
    "    ResponseSchema(name=\"summary\", description=\"ë¦¬ë·°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½\")\n",
    "]\n",
    "\n",
    "# íŒŒì„œ ì´ˆê¸°í™”\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "print(\"ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­:\")\n",
    "print(format_instructions)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "template = \"\"\"\n",
    "ë‹¤ìŒ ì œí’ˆ ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ì„¸ìš”. ë¦¬ë·° ë‚´ìš©: {review}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(format_instructions=format_instructions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68011d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ë¶„ì„ ê²°ê³¼ =====\n",
      "{'cons': ['ê°€ê²©ì´ ë¹„ìŒˆ', 'ë¬´ê²Œê°€ 200g ì´ìƒì„', 'ì†ì´ í”¼ê³¤í•  ìˆ˜ ìˆìŒ'],\n",
      " 'pros': ['ë°°í„°ë¦¬ ìˆ˜ëª…ì´ ì¢‹ìŒ', 'ì¹´ë©”ë¼ í™”ì§ˆì´ ì„ ëª…í•¨', 'ì•¼ê°„ ëª¨ë“œê°€ í›Œë¥­í•¨'],\n",
      " 'rating': '4',\n",
      " 'summary': 'ìŠ¤ë§ˆíŠ¸í°ì˜ ë°°í„°ë¦¬ ìˆ˜ëª…ê³¼ ì¹´ë©”ë¼ í™”ì§ˆì€ ìš°ìˆ˜í•˜ë‚˜, ê°€ê²©ì´ ë¹„ì‹¸ê³  ë¬´ê²Œê°€ ë¬´ê±°ì›Œì„œ ì†ì´ í”¼ê³¤í•  ìˆ˜ ìˆìŒ.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™” (temperature=0.5ë¡œ ì„¤ì •í•´ ì¼ê´€ì„± ìˆëŠ” ì¶œë ¥)\n",
    "#model = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë¦¬ë·° ë°ì´í„°\n",
    "review = \"\"\"\n",
    "ì´ ìŠ¤ë§ˆíŠ¸í°ì€ ë°°í„°ë¦¬ ìˆ˜ëª…ì´ ì •ë§ ì¢‹ì•„ì„œ í•˜ë£¨ ì¢…ì¼ ì‚¬ìš©í•´ë„ ì¶©ì „ì´ í•„ìš” ì—†ì—ˆì–´ìš”. \n",
    "ì¹´ë©”ë¼ í™”ì§ˆë„ ì„ ëª…í•˜ê³ , íŠ¹íˆ ì•¼ê°„ ëª¨ë“œê°€ í›Œë¥­í•©ë‹ˆë‹¤. \n",
    "ë‹¤ë§Œ ê°€ê²©ì´ ì¡°ê¸ˆ ë¹„ì‹¸ê³ , ë¬´ê²Œê°€ 200gì´ ë„˜ì–´ì„œ ì†ì´ í”¼ê³¤í•  ìˆ˜ ìˆì–´ìš”.\n",
    "\"\"\"\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "chain = prompt | model | parser\n",
    "\n",
    "output = chain.invoke({\"review\": review})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥ (Pretty Print)\n",
    "print(\"===== ë¶„ì„ ê²°ê³¼ =====\")\n",
    "pprint(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3495072",
   "metadata": {},
   "source": [
    "### DatetimeOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6a5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
